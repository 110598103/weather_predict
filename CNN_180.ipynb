{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a5f579c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "#from tensorflow import keras\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.models import Sequential,load_model\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import TimeDistributed\n",
    "from tensorflow.keras.layers import Lambda,Reshape\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import ConvLSTM2D\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.regularizers import l1,l2,l1_l2\n",
    "from tensorflow.keras.models import Sequential  #用來啟動 NN\n",
    "from tensorflow.keras.layers import Conv2D  # Convolution Operation\n",
    "from tensorflow.keras.layers import MaxPooling2D # Pooling\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense # Fully Connected Networks\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import concatenate, AveragePooling2D, UpSampling2D, add, Multiply, GlobalAveragePooling2D\n",
    "import tensorflow.keras as keras  \n",
    "from tensorflow.keras import backend as K\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import time\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "556856ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_collect(Path):\n",
    "    files=os.listdir(Path)\n",
    "    random.shuffle(files)\n",
    "    Train_Lstm=[]\n",
    "    Label=[]\n",
    "    Train=[]\n",
    "    Train\n",
    "    count=1\n",
    "    Train_Pdf=[]\n",
    "    for file in files:\n",
    "        start=time.time()\n",
    "        Break=0\n",
    "        global Train_pdf, Label_Pdf\n",
    "        Train_lstm=[]\n",
    "        file_data=os.listdir(Path+file)\n",
    "        \n",
    "        ##CNN_PDF\n",
    "        #CSFV2\n",
    "        df_csfv2 = pd.read_csv(Path+file+'/'+file_data[0],header=None)\n",
    "        df_era5 = pd.read_csv(Path+file+'/'+file_data[1],header=None)\n",
    "        for column in df_csfv2.columns[2:7]:\n",
    "            if column == df_csfv2.columns[2]:\n",
    "                Train_pdf=np.array(np.array(df_csfv2[column]).reshape(61,101,1))\n",
    "            else:\n",
    "                Train_pdf=np.append(Train_pdf,np.array(df_csfv2[column]).reshape(61,101,1),axis=2)\n",
    "                \n",
    "        #ERAF\n",
    "        for column in df_era5.columns[2:12]:\n",
    "            Train_pdf=np.append(Train_pdf,np.array(df_era5[column]).reshape(61,101,1),axis=2)\n",
    "\n",
    "        ##LSTM\n",
    "        #ERA5\n",
    "        df_1 = pd.read_csv(Path+file+'/'+file_data[3])\n",
    "        for column in df_1.columns[1:91]:\n",
    "            if' NaN' in list(df_1[column])[:]:\n",
    "                Break=1\n",
    "                break\n",
    "            Train_lstm.append(list(df_1[column]))\n",
    "            \n",
    "        #CSFV2\n",
    "        df_2 = pd.read_csv(Path+file+'/'+file_data[2])\n",
    "        for column in df_2.columns[1:181]:\n",
    "            if' NaN' in list(df_2[column])[:]:\n",
    "                Break=1\n",
    "                break\n",
    "            Train_lstm.append(list(df_2[column]))\n",
    "        if Break==1:\n",
    "            continue\n",
    "\n",
    "        ##LABEL_PDF \n",
    "        for column in df_era5.columns[7:17]:\n",
    "            if column == df_era5.columns[7]:\n",
    "                Label_Pdf=np.array(np.array(df_era5[column]).reshape(61,101,1))\n",
    "                #print(Label_Pdf)\n",
    "            else:\n",
    "                Label_Pdf=np.append(Label_Pdf,np.array(df_era5[column]).reshape(61,101,1),axis=2)\n",
    "\n",
    "        Train_Pdf.append(Train_pdf)\n",
    "        Train_Lstm.append(Train_lstm)\n",
    "        Label.append(Label_Pdf)\n",
    "        end=time.time()\n",
    "        Time=(end-start)*(len(files)-count)\n",
    "        print('%d / %d , Time : %d : %d : %d'%(count,len(files),int(Time/3600),int(Time%3600/60),Time%3600%60),end='\\r')\n",
    "        count=count+1\n",
    "    Train.append(Train_Pdf)\n",
    "    Train.append(Train_Lstm)\n",
    "    Label=np.array(Label)\n",
    "    return Train,Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ca2a2ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2771 / 2862 , Time : 0 : 0 : 37\r"
     ]
    }
   ],
   "source": [
    "#資料位置\n",
    "Path='Data/Train/'\n",
    "\n",
    "#模型儲存位置\n",
    "Path_model = 'Model/LSMT_Restnet_new_data_my_loss_only_CNN_180days.h5'\n",
    "\n",
    "#載入資料\n",
    "Train,Label=data_collect(Path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee9d5714",
   "metadata": {},
   "outputs": [],
   "source": [
    "def squeeze_excitation(out_dim, nb_filter):\n",
    "    def f(input):\n",
    "        squeeze = GlobalAveragePooling2D()(input)\n",
    "        excitation = Dense(int(out_dim/2), activation='relu')(squeeze)\n",
    "        excitation = Dense(out_dim, activation='sigmoid')(excitation)\n",
    "        excitation = Reshape((1,1,out_dim))(excitation)\n",
    "        return Multiply()([input, excitation])\n",
    "    return f\n",
    "\n",
    "\n",
    "def squeeze_excitation_layer(out_dim, nb_filter):\n",
    "    def f(input):\n",
    "        input = squeeze_excitation(out_dim, nb_filter)(input)\n",
    "        return input\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a70bc606",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Conv2D_BN(inputs,filter,kernel,padding,stride):\n",
    "    outputs = keras.layers.Conv2D(filters=filter,kernel_size=kernel,padding=padding,strides=stride,activation='relu')(inputs)\n",
    "    outputs = keras.layers.BatchNormalization()(outputs)\n",
    "    return outputs\n",
    "\n",
    "def residual_block(inputs,filter,stride,whether_identity_change=False):\n",
    "    x = Conv2D_BN(inputs, filter[0], kernel=(1,1), padding='same', stride=stride) \n",
    "    x = Conv2D_BN(x, filter[1], kernel=(3,3), padding='same', stride=1)\n",
    "    x = Conv2D_BN(x, filter[2] ,kernel=(1,1), padding='same', stride=1)\n",
    "    x = squeeze_excitation_layer(x.shape[-1], x.shape[-1])(x)\n",
    "  # 累加必须保持尺寸一致，控制恒等层是否需要变channel数和压缩尺寸\n",
    "    if whether_identity_change:\n",
    "        identity = Conv2D_BN(inputs, filter[2], kernel=(1,1), padding='same', stride=stride)\n",
    "        x = keras.layers.add([x,identity])\n",
    "        return x\n",
    "    else:\n",
    "        x = keras.layers.add([x,inputs])\n",
    "        return x\n",
    "    \n",
    "def ResNet():\n",
    "  inputs = keras.Input(shape=(61, 101, 15))\n",
    "  x = Conv2D_BN(inputs,64,(7,7),'same',2)\n",
    "  x = keras.layers.MaxPool2D(pool_size=(3,3), strides=2, padding='same')(x)\n",
    "\n",
    "  x = residual_block(x,[64,64,256],1,True)\n",
    "  x = residual_block(x,[64,64,256],1)\n",
    "  x = residual_block(x,[64,64,256],1)\n",
    "\n",
    "  x = residual_block(x,[128,128,512],2,True)\n",
    "  x = residual_block(x,[128,128,512],1)\n",
    "  x = residual_block(x,[128,128,512],1)\n",
    "  x = residual_block(x,[128,128,512],1)\n",
    "\n",
    "  x = residual_block(x,[256,256,1024],2,True)\n",
    "  x = residual_block(x,[256,256,1024],1)\n",
    "  x = residual_block(x,[256,256,1024],1)\n",
    "  x = residual_block(x,[256,256,1024],1)\n",
    "  x = residual_block(x,[256,256,1024],1)\n",
    "  x = residual_block(x,[256,256,1024],1)\n",
    "\n",
    "  x = residual_block(x,[512,512,2048],2,True)\n",
    "  x = residual_block(x,[512,512,2048],1)\n",
    "  x = residual_block(x,[512,512,2048],1) \n",
    "  x = keras.layers.AveragePooling2D(pool_size=(x.shape[1],x.shape[2]))(x)  \n",
    "  x = keras.layers.Flatten()(x)\n",
    "  x = keras.layers.Dense(10000,activation='relu')(x)\n",
    "  x = Dense(10000, activation='relu')(x)\n",
    "  x = Dense(101*61*10, activation='linear')(x)\n",
    "  x = Reshape((61,101,10))(x)\n",
    "  model = keras.Model(inputs=inputs,outputs=x)\n",
    "  model.summary()\n",
    "  return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f93787c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 61, 101, 15) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_106 (Conv2D)             (None, 31, 51, 64)   47104       input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_106 (BatchN (None, 31, 51, 64)   256         conv2d_106[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 16, 26, 64)   0           batch_normalization_106[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_107 (Conv2D)             (None, 16, 26, 64)   4160        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_107 (BatchN (None, 16, 26, 64)   256         conv2d_107[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_108 (Conv2D)             (None, 16, 26, 64)   36928       batch_normalization_107[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_108 (BatchN (None, 16, 26, 64)   256         conv2d_108[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_109 (Conv2D)             (None, 16, 26, 256)  16640       batch_normalization_108[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_109 (BatchN (None, 16, 26, 256)  1024        conv2d_109[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_32 (Gl (None, 256)          0           batch_normalization_109[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_68 (Dense)                (None, 128)          32896       global_average_pooling2d_32[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dense_69 (Dense)                (None, 256)          33024       dense_68[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_33 (Reshape)            (None, 1, 1, 256)    0           dense_69[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_110 (Conv2D)             (None, 16, 26, 256)  16640       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_32 (Multiply)          (None, 16, 26, 256)  0           batch_normalization_109[0][0]    \n",
      "                                                                 reshape_33[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_110 (BatchN (None, 16, 26, 256)  1024        conv2d_110[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_32 (Add)                    (None, 16, 26, 256)  0           multiply_32[0][0]                \n",
      "                                                                 batch_normalization_110[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_111 (Conv2D)             (None, 16, 26, 64)   16448       add_32[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_111 (BatchN (None, 16, 26, 64)   256         conv2d_111[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_112 (Conv2D)             (None, 16, 26, 64)   36928       batch_normalization_111[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_112 (BatchN (None, 16, 26, 64)   256         conv2d_112[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_113 (Conv2D)             (None, 16, 26, 256)  16640       batch_normalization_112[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_113 (BatchN (None, 16, 26, 256)  1024        conv2d_113[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_33 (Gl (None, 256)          0           batch_normalization_113[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_70 (Dense)                (None, 128)          32896       global_average_pooling2d_33[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dense_71 (Dense)                (None, 256)          33024       dense_70[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_34 (Reshape)            (None, 1, 1, 256)    0           dense_71[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_33 (Multiply)          (None, 16, 26, 256)  0           batch_normalization_113[0][0]    \n",
      "                                                                 reshape_34[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_33 (Add)                    (None, 16, 26, 256)  0           multiply_33[0][0]                \n",
      "                                                                 add_32[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_114 (Conv2D)             (None, 16, 26, 64)   16448       add_33[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_114 (BatchN (None, 16, 26, 64)   256         conv2d_114[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_115 (Conv2D)             (None, 16, 26, 64)   36928       batch_normalization_114[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_115 (BatchN (None, 16, 26, 64)   256         conv2d_115[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_116 (Conv2D)             (None, 16, 26, 256)  16640       batch_normalization_115[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_116 (BatchN (None, 16, 26, 256)  1024        conv2d_116[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_34 (Gl (None, 256)          0           batch_normalization_116[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_72 (Dense)                (None, 128)          32896       global_average_pooling2d_34[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dense_73 (Dense)                (None, 256)          33024       dense_72[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_35 (Reshape)            (None, 1, 1, 256)    0           dense_73[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_34 (Multiply)          (None, 16, 26, 256)  0           batch_normalization_116[0][0]    \n",
      "                                                                 reshape_35[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_34 (Add)                    (None, 16, 26, 256)  0           multiply_34[0][0]                \n",
      "                                                                 add_33[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_117 (Conv2D)             (None, 8, 13, 128)   32896       add_34[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_117 (BatchN (None, 8, 13, 128)   512         conv2d_117[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_118 (Conv2D)             (None, 8, 13, 128)   147584      batch_normalization_117[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_118 (BatchN (None, 8, 13, 128)   512         conv2d_118[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_119 (Conv2D)             (None, 8, 13, 512)   66048       batch_normalization_118[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_119 (BatchN (None, 8, 13, 512)   2048        conv2d_119[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_35 (Gl (None, 512)          0           batch_normalization_119[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_74 (Dense)                (None, 256)          131328      global_average_pooling2d_35[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dense_75 (Dense)                (None, 512)          131584      dense_74[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_36 (Reshape)            (None, 1, 1, 512)    0           dense_75[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_120 (Conv2D)             (None, 8, 13, 512)   131584      add_34[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_35 (Multiply)          (None, 8, 13, 512)   0           batch_normalization_119[0][0]    \n",
      "                                                                 reshape_36[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_120 (BatchN (None, 8, 13, 512)   2048        conv2d_120[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_35 (Add)                    (None, 8, 13, 512)   0           multiply_35[0][0]                \n",
      "                                                                 batch_normalization_120[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_121 (Conv2D)             (None, 8, 13, 128)   65664       add_35[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_121 (BatchN (None, 8, 13, 128)   512         conv2d_121[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_122 (Conv2D)             (None, 8, 13, 128)   147584      batch_normalization_121[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_122 (BatchN (None, 8, 13, 128)   512         conv2d_122[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_123 (Conv2D)             (None, 8, 13, 512)   66048       batch_normalization_122[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_123 (BatchN (None, 8, 13, 512)   2048        conv2d_123[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_36 (Gl (None, 512)          0           batch_normalization_123[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_76 (Dense)                (None, 256)          131328      global_average_pooling2d_36[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dense_77 (Dense)                (None, 512)          131584      dense_76[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_37 (Reshape)            (None, 1, 1, 512)    0           dense_77[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_36 (Multiply)          (None, 8, 13, 512)   0           batch_normalization_123[0][0]    \n",
      "                                                                 reshape_37[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_36 (Add)                    (None, 8, 13, 512)   0           multiply_36[0][0]                \n",
      "                                                                 add_35[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_124 (Conv2D)             (None, 8, 13, 128)   65664       add_36[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_124 (BatchN (None, 8, 13, 128)   512         conv2d_124[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_125 (Conv2D)             (None, 8, 13, 128)   147584      batch_normalization_124[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_125 (BatchN (None, 8, 13, 128)   512         conv2d_125[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_126 (Conv2D)             (None, 8, 13, 512)   66048       batch_normalization_125[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_126 (BatchN (None, 8, 13, 512)   2048        conv2d_126[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_37 (Gl (None, 512)          0           batch_normalization_126[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_78 (Dense)                (None, 256)          131328      global_average_pooling2d_37[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dense_79 (Dense)                (None, 512)          131584      dense_78[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_38 (Reshape)            (None, 1, 1, 512)    0           dense_79[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_37 (Multiply)          (None, 8, 13, 512)   0           batch_normalization_126[0][0]    \n",
      "                                                                 reshape_38[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_37 (Add)                    (None, 8, 13, 512)   0           multiply_37[0][0]                \n",
      "                                                                 add_36[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_127 (Conv2D)             (None, 8, 13, 128)   65664       add_37[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_127 (BatchN (None, 8, 13, 128)   512         conv2d_127[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_128 (Conv2D)             (None, 8, 13, 128)   147584      batch_normalization_127[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_128 (BatchN (None, 8, 13, 128)   512         conv2d_128[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_129 (Conv2D)             (None, 8, 13, 512)   66048       batch_normalization_128[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_129 (BatchN (None, 8, 13, 512)   2048        conv2d_129[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_38 (Gl (None, 512)          0           batch_normalization_129[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_80 (Dense)                (None, 256)          131328      global_average_pooling2d_38[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dense_81 (Dense)                (None, 512)          131584      dense_80[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_39 (Reshape)            (None, 1, 1, 512)    0           dense_81[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_38 (Multiply)          (None, 8, 13, 512)   0           batch_normalization_129[0][0]    \n",
      "                                                                 reshape_39[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_38 (Add)                    (None, 8, 13, 512)   0           multiply_38[0][0]                \n",
      "                                                                 add_37[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_130 (Conv2D)             (None, 4, 7, 256)    131328      add_38[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_130 (BatchN (None, 4, 7, 256)    1024        conv2d_130[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_131 (Conv2D)             (None, 4, 7, 256)    590080      batch_normalization_130[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_131 (BatchN (None, 4, 7, 256)    1024        conv2d_131[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_132 (Conv2D)             (None, 4, 7, 1024)   263168      batch_normalization_131[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_132 (BatchN (None, 4, 7, 1024)   4096        conv2d_132[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_39 (Gl (None, 1024)         0           batch_normalization_132[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_82 (Dense)                (None, 512)          524800      global_average_pooling2d_39[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dense_83 (Dense)                (None, 1024)         525312      dense_82[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_40 (Reshape)            (None, 1, 1, 1024)   0           dense_83[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_133 (Conv2D)             (None, 4, 7, 1024)   525312      add_38[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_39 (Multiply)          (None, 4, 7, 1024)   0           batch_normalization_132[0][0]    \n",
      "                                                                 reshape_40[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_133 (BatchN (None, 4, 7, 1024)   4096        conv2d_133[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_39 (Add)                    (None, 4, 7, 1024)   0           multiply_39[0][0]                \n",
      "                                                                 batch_normalization_133[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_134 (Conv2D)             (None, 4, 7, 256)    262400      add_39[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_134 (BatchN (None, 4, 7, 256)    1024        conv2d_134[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_135 (Conv2D)             (None, 4, 7, 256)    590080      batch_normalization_134[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_135 (BatchN (None, 4, 7, 256)    1024        conv2d_135[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_136 (Conv2D)             (None, 4, 7, 1024)   263168      batch_normalization_135[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_136 (BatchN (None, 4, 7, 1024)   4096        conv2d_136[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_40 (Gl (None, 1024)         0           batch_normalization_136[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_84 (Dense)                (None, 512)          524800      global_average_pooling2d_40[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dense_85 (Dense)                (None, 1024)         525312      dense_84[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_41 (Reshape)            (None, 1, 1, 1024)   0           dense_85[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_40 (Multiply)          (None, 4, 7, 1024)   0           batch_normalization_136[0][0]    \n",
      "                                                                 reshape_41[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_40 (Add)                    (None, 4, 7, 1024)   0           multiply_40[0][0]                \n",
      "                                                                 add_39[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_137 (Conv2D)             (None, 4, 7, 256)    262400      add_40[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_137 (BatchN (None, 4, 7, 256)    1024        conv2d_137[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_138 (Conv2D)             (None, 4, 7, 256)    590080      batch_normalization_137[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_138 (BatchN (None, 4, 7, 256)    1024        conv2d_138[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_139 (Conv2D)             (None, 4, 7, 1024)   263168      batch_normalization_138[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_139 (BatchN (None, 4, 7, 1024)   4096        conv2d_139[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_41 (Gl (None, 1024)         0           batch_normalization_139[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_86 (Dense)                (None, 512)          524800      global_average_pooling2d_41[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dense_87 (Dense)                (None, 1024)         525312      dense_86[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_42 (Reshape)            (None, 1, 1, 1024)   0           dense_87[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_41 (Multiply)          (None, 4, 7, 1024)   0           batch_normalization_139[0][0]    \n",
      "                                                                 reshape_42[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_41 (Add)                    (None, 4, 7, 1024)   0           multiply_41[0][0]                \n",
      "                                                                 add_40[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_140 (Conv2D)             (None, 4, 7, 256)    262400      add_41[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_140 (BatchN (None, 4, 7, 256)    1024        conv2d_140[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_141 (Conv2D)             (None, 4, 7, 256)    590080      batch_normalization_140[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_141 (BatchN (None, 4, 7, 256)    1024        conv2d_141[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_142 (Conv2D)             (None, 4, 7, 1024)   263168      batch_normalization_141[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_142 (BatchN (None, 4, 7, 1024)   4096        conv2d_142[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_42 (Gl (None, 1024)         0           batch_normalization_142[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_88 (Dense)                (None, 512)          524800      global_average_pooling2d_42[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dense_89 (Dense)                (None, 1024)         525312      dense_88[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_43 (Reshape)            (None, 1, 1, 1024)   0           dense_89[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_42 (Multiply)          (None, 4, 7, 1024)   0           batch_normalization_142[0][0]    \n",
      "                                                                 reshape_43[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_42 (Add)                    (None, 4, 7, 1024)   0           multiply_42[0][0]                \n",
      "                                                                 add_41[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_143 (Conv2D)             (None, 4, 7, 256)    262400      add_42[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_143 (BatchN (None, 4, 7, 256)    1024        conv2d_143[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_144 (Conv2D)             (None, 4, 7, 256)    590080      batch_normalization_143[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_144 (BatchN (None, 4, 7, 256)    1024        conv2d_144[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_145 (Conv2D)             (None, 4, 7, 1024)   263168      batch_normalization_144[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_145 (BatchN (None, 4, 7, 1024)   4096        conv2d_145[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_43 (Gl (None, 1024)         0           batch_normalization_145[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_90 (Dense)                (None, 512)          524800      global_average_pooling2d_43[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dense_91 (Dense)                (None, 1024)         525312      dense_90[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_44 (Reshape)            (None, 1, 1, 1024)   0           dense_91[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_43 (Multiply)          (None, 4, 7, 1024)   0           batch_normalization_145[0][0]    \n",
      "                                                                 reshape_44[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_43 (Add)                    (None, 4, 7, 1024)   0           multiply_43[0][0]                \n",
      "                                                                 add_42[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_146 (Conv2D)             (None, 4, 7, 256)    262400      add_43[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_146 (BatchN (None, 4, 7, 256)    1024        conv2d_146[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_147 (Conv2D)             (None, 4, 7, 256)    590080      batch_normalization_146[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_147 (BatchN (None, 4, 7, 256)    1024        conv2d_147[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_148 (Conv2D)             (None, 4, 7, 1024)   263168      batch_normalization_147[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_148 (BatchN (None, 4, 7, 1024)   4096        conv2d_148[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_44 (Gl (None, 1024)         0           batch_normalization_148[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_92 (Dense)                (None, 512)          524800      global_average_pooling2d_44[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dense_93 (Dense)                (None, 1024)         525312      dense_92[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_45 (Reshape)            (None, 1, 1, 1024)   0           dense_93[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_44 (Multiply)          (None, 4, 7, 1024)   0           batch_normalization_148[0][0]    \n",
      "                                                                 reshape_45[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_44 (Add)                    (None, 4, 7, 1024)   0           multiply_44[0][0]                \n",
      "                                                                 add_43[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_149 (Conv2D)             (None, 2, 4, 512)    524800      add_44[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_149 (BatchN (None, 2, 4, 512)    2048        conv2d_149[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_150 (Conv2D)             (None, 2, 4, 512)    2359808     batch_normalization_149[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_150 (BatchN (None, 2, 4, 512)    2048        conv2d_150[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_151 (Conv2D)             (None, 2, 4, 2048)   1050624     batch_normalization_150[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_151 (BatchN (None, 2, 4, 2048)   8192        conv2d_151[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_45 (Gl (None, 2048)         0           batch_normalization_151[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_94 (Dense)                (None, 1024)         2098176     global_average_pooling2d_45[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dense_95 (Dense)                (None, 2048)         2099200     dense_94[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_46 (Reshape)            (None, 1, 1, 2048)   0           dense_95[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_152 (Conv2D)             (None, 2, 4, 2048)   2099200     add_44[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_45 (Multiply)          (None, 2, 4, 2048)   0           batch_normalization_151[0][0]    \n",
      "                                                                 reshape_46[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_152 (BatchN (None, 2, 4, 2048)   8192        conv2d_152[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_45 (Add)                    (None, 2, 4, 2048)   0           multiply_45[0][0]                \n",
      "                                                                 batch_normalization_152[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_153 (Conv2D)             (None, 2, 4, 512)    1049088     add_45[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_153 (BatchN (None, 2, 4, 512)    2048        conv2d_153[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_154 (Conv2D)             (None, 2, 4, 512)    2359808     batch_normalization_153[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_154 (BatchN (None, 2, 4, 512)    2048        conv2d_154[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_155 (Conv2D)             (None, 2, 4, 2048)   1050624     batch_normalization_154[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_155 (BatchN (None, 2, 4, 2048)   8192        conv2d_155[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_46 (Gl (None, 2048)         0           batch_normalization_155[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_96 (Dense)                (None, 1024)         2098176     global_average_pooling2d_46[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dense_97 (Dense)                (None, 2048)         2099200     dense_96[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_47 (Reshape)            (None, 1, 1, 2048)   0           dense_97[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_46 (Multiply)          (None, 2, 4, 2048)   0           batch_normalization_155[0][0]    \n",
      "                                                                 reshape_47[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_46 (Add)                    (None, 2, 4, 2048)   0           multiply_46[0][0]                \n",
      "                                                                 add_45[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_156 (Conv2D)             (None, 2, 4, 512)    1049088     add_46[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_156 (BatchN (None, 2, 4, 512)    2048        conv2d_156[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_157 (Conv2D)             (None, 2, 4, 512)    2359808     batch_normalization_156[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_157 (BatchN (None, 2, 4, 512)    2048        conv2d_157[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_158 (Conv2D)             (None, 2, 4, 2048)   1050624     batch_normalization_157[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_158 (BatchN (None, 2, 4, 2048)   8192        conv2d_158[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_47 (Gl (None, 2048)         0           batch_normalization_158[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_98 (Dense)                (None, 1024)         2098176     global_average_pooling2d_47[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dense_99 (Dense)                (None, 2048)         2099200     dense_98[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_48 (Reshape)            (None, 1, 1, 2048)   0           dense_99[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_47 (Multiply)          (None, 2, 4, 2048)   0           batch_normalization_158[0][0]    \n",
      "                                                                 reshape_48[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_47 (Add)                    (None, 2, 4, 2048)   0           multiply_47[0][0]                \n",
      "                                                                 add_46[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 1, 1, 2048)   0           add_47[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 2048)         0           average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_100 (Dense)               (None, 10000)        20490000    flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_101 (Dense)               (None, 10000)        100010000   dense_100[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_102 (Dense)               (None, 61610)        616161610   dense_101[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_49 (Reshape)            (None, 61, 101, 10)  0           dense_102[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 780,429,162\n",
      "Trainable params: 780,376,042\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = (61, 101, 15)\n",
    "model=ResNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c25b954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_Lstm: (2771, 270, 10)\n",
      "Train_Pdf: (2771, 61, 101, 15)\n"
     ]
    }
   ],
   "source": [
    "#資料轉換格式\n",
    "Train_Pdf=Train[0]\n",
    "Train_Lstm=Train[1]\n",
    "Train_Pdf=np.array(Train_Pdf)\n",
    "Train_Lstm=np.array(Train_Lstm)\n",
    "print('Train_Lstm:',Train_Lstm.shape)\n",
    "print('Train_Pdf:',Train_Pdf.shape)\n",
    "Train_Pdf_List=Train_Pdf.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e91a28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#儲存最大、最小、平均值\n",
    "Max=[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
    "Min=[1000,1000,1000,1000,1000,1000,1000,1000,1000,1000,1000,1000,1000,1000,1000]\n",
    "Mean=[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
    "count=0\n",
    "for i in range(len(Train_Pdf_List)):\n",
    "    for j in range(len(Train_Pdf_List[0])):\n",
    "        for x in range(len(Train_Pdf_List[0][0])):\n",
    "            for y in range(len(Train_Pdf_List[0][0][0])):\n",
    "                if Train_Pdf_List[i][j][x][y]>Max[y]:\n",
    "                    Max[y]=Train_Pdf_List[i][j][x][y]\n",
    "                if Train_Pdf_List[i][j][x][y]<Min[y]:\n",
    "                    Min[y]=Train_Pdf_List[i][j][x][y]\n",
    "                Mean[y]=Mean[y]+Train_Pdf_List[i][j][x][y] \n",
    "            count=count+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1b30fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Max=Max[:10]\n",
    "Min=Min[:10]\n",
    "Mean=Mean[:10]\n",
    "for i in range(10):\n",
    "    Mean[i]=Mean[i]/count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2f221eef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: [287.3242734287198, 3.349621542723795, 293.65658980295865, 279.6666574399456, -0.25665387472126, 288.3584796428863, 3.2974777666300223, 294.7044402373835, 281.08416123969715, -0.15500007492913936]\n",
      "Max: [307.9367, 17.7063, 313.7215, 304.4253, 3.8382, 310.1568, 18.0352, 314.7128, 306.1226, 2.7172]\n",
      "Min: [232.6118, 0.1771, 244.0102, 204.4635, -4.7362, 234.9248, 0.1928, 248.2585, 220.1559, -4.1973]\n"
     ]
    }
   ],
   "source": [
    "print('Mean:',Mean)\n",
    "print('Max:',Max)\n",
    "print('Min:',Min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "235ee005",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mcustom_loss(y_true, y_pred):\n",
    "\n",
    "    trueAvg = (y_true[:,:,:,0][:,:,:,np.newaxis]-Mean[0])/(Max[0]-Min[0])\n",
    "    trueStd = (y_true[:,:,:,1][:,:,:,np.newaxis]-Mean[1])/(Max[1]-Min[1])\n",
    "    trueMax = (y_true[:,:,:,2][:,:,:,np.newaxis]-Mean[2])/(Max[2]-Min[2])\n",
    "    trueMin = (y_true[:,:,:,3][:,:,:,np.newaxis]-Mean[3])/(Max[3]-Min[3])\n",
    "    trueSkw = (y_true[:,:,:,4][:,:,:,np.newaxis]-Mean[4])/(Max[4]-Min[4])\n",
    "\n",
    "    predAvg = (y_pred[:,:,:,0][:,:,:,np.newaxis]-Mean[0])/(Max[0]-Min[0])\n",
    "    predStd = (y_pred[:,:,:,1][:,:,:,np.newaxis]-Mean[1])/(Max[1]-Min[1])\n",
    "    predMax = (y_pred[:,:,:,2][:,:,:,np.newaxis]-Mean[2])/(Max[2]-Min[2])\n",
    "    predMin = (y_pred[:,:,:,3][:,:,:,np.newaxis]-Mean[3])/(Max[3]-Min[3])\n",
    "    predSkw = (y_pred[:,:,:,4][:,:,:,np.newaxis]-Mean[4])/(Max[4]-Min[4])\n",
    "    \n",
    "    trueAvg_180 = (y_true[:,:,:,5][:,:,:,np.newaxis]-Mean[5])/(Max[5]-Min[5])\n",
    "    trueStd_180 = (y_true[:,:,:,6][:,:,:,np.newaxis]-Mean[6])/(Max[6]-Min[6])\n",
    "    trueMax_180 = (y_true[:,:,:,7][:,:,:,np.newaxis]-Mean[7])/(Max[7]-Min[7])\n",
    "    trueMin_180 = (y_true[:,:,:,8][:,:,:,np.newaxis]-Mean[8])/(Max[8]-Min[8])\n",
    "    trueSkw_180 = (y_true[:,:,:,9][:,:,:,np.newaxis]-Mean[9])/(Max[9]-Min[9])\n",
    "\n",
    "    predAvg_180 = (y_pred[:,:,:,5][:,:,:,np.newaxis]-Mean[5])/(Max[5]-Min[5])\n",
    "    predStd_180 = (y_pred[:,:,:,6][:,:,:,np.newaxis]-Mean[6])/(Max[6]-Min[6])\n",
    "    predMax_180 = (y_pred[:,:,:,7][:,:,:,np.newaxis]-Mean[7])/(Max[7]-Min[7])\n",
    "    predMin_180 = (y_pred[:,:,:,8][:,:,:,np.newaxis]-Mean[8])/(Max[8]-Min[8])\n",
    "    predSkw_180 = (y_pred[:,:,:,9][:,:,:,np.newaxis]-Mean[9])/(Max[9]-Min[9])\n",
    "\n",
    "    loss = ((K.square(predMin - trueMin) + K.square(predMax - trueMax) + K.square(predSkw - trueSkw) +\n",
    "            K.square(predAvg - trueAvg) + K.square(predStd - trueStd))+\n",
    "            (K.square(predMin_180 - trueMin_180) + K.square(predMax_180 - trueMax_180) + K.square(predSkw_180 - trueSkw_180) +\n",
    "            K.square(predAvg_180 - trueAvg_180) + K.square(predStd_180 - trueStd_180)))/10\n",
    "    loss = K.mean(loss, axis=-1)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0763ea29",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "139/139 [==============================] - ETA: 0s - loss: 1.5636\n",
      "Epoch 00001: val_loss improved from inf to 2.34439, saving model to D:/weather/model\\LSMT_Restnet_new_data_my_loss_only_CNN_180days.h5\n",
      "139/139 [==============================] - 667s 5s/step - loss: 1.5636 - val_loss: 2.3444\n",
      "Epoch 2/100\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.0242\n",
      "Epoch 00002: val_loss improved from 2.34439 to 0.25159, saving model to D:/weather/model\\LSMT_Restnet_new_data_my_loss_only_CNN_180days.h5\n",
      "139/139 [==============================] - 403s 3s/step - loss: 0.0242 - val_loss: 0.2516\n",
      "Epoch 3/100\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.0120\n",
      "Epoch 00003: val_loss improved from 0.25159 to 0.00813, saving model to D:/weather/model\\LSMT_Restnet_new_data_my_loss_only_CNN_180days.h5\n",
      "139/139 [==============================] - 415s 3s/step - loss: 0.0120 - val_loss: 0.0081\n",
      "Epoch 4/100\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.0216\n",
      "Epoch 00004: val_loss did not improve from 0.00813\n",
      "139/139 [==============================] - 343s 2s/step - loss: 0.0216 - val_loss: 5.7815\n",
      "Epoch 5/100\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.0849\n",
      "Epoch 00005: val_loss did not improve from 0.00813\n",
      "139/139 [==============================] - 338s 2s/step - loss: 0.0849 - val_loss: 8037.3188\n",
      "Epoch 6/100\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.0244\n",
      "Epoch 00006: val_loss did not improve from 0.00813\n",
      "139/139 [==============================] - 341s 2s/step - loss: 0.0244 - val_loss: 1.9385\n",
      "Epoch 7/100\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.0138\n",
      "Epoch 00007: val_loss did not improve from 0.00813\n",
      "139/139 [==============================] - 345s 2s/step - loss: 0.0138 - val_loss: 0.0110\n",
      "Epoch 8/100\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.0103\n",
      "Epoch 00008: val_loss did not improve from 0.00813\n",
      "139/139 [==============================] - 345s 2s/step - loss: 0.0103 - val_loss: 0.0148\n",
      "Epoch 9/100\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.0070\n",
      "Epoch 00009: val_loss improved from 0.00813 to 0.00756, saving model to D:/weather/model\\LSMT_Restnet_new_data_my_loss_only_CNN_180days.h5\n",
      "139/139 [==============================] - 405s 3s/step - loss: 0.0070 - val_loss: 0.0076\n",
      "Epoch 10/100\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.0074\n",
      "Epoch 00010: val_loss did not improve from 0.00756\n",
      "139/139 [==============================] - 342s 2s/step - loss: 0.0074 - val_loss: 0.0152\n",
      "Epoch 11/100\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.0091\n",
      "Epoch 00011: val_loss improved from 0.00756 to 0.00500, saving model to D:/weather/model\\LSMT_Restnet_new_data_my_loss_only_CNN_180days.h5\n",
      "139/139 [==============================] - 417s 3s/step - loss: 0.0091 - val_loss: 0.0050\n",
      "Epoch 12/100\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.0067\n",
      "Epoch 00012: val_loss did not improve from 0.00500\n",
      "139/139 [==============================] - 345s 2s/step - loss: 0.0067 - val_loss: 0.0122\n",
      "Epoch 13/100\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.0064\n",
      "Epoch 00013: val_loss did not improve from 0.00500\n",
      "139/139 [==============================] - 350s 3s/step - loss: 0.0064 - val_loss: 0.0197\n",
      "Epoch 14/100\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.0093\n",
      "Epoch 00014: val_loss did not improve from 0.00500\n",
      "139/139 [==============================] - 335s 2s/step - loss: 0.0093 - val_loss: 0.0218\n",
      "Epoch 15/100\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.0157\n",
      "Epoch 00015: val_loss did not improve from 0.00500\n",
      "139/139 [==============================] - 334s 2s/step - loss: 0.0157 - val_loss: 0.0072\n",
      "Epoch 16/100\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.0094\n",
      "Epoch 00016: val_loss did not improve from 0.00500\n",
      "139/139 [==============================] - 334s 2s/step - loss: 0.0094 - val_loss: 0.0176\n",
      "Epoch 17/100\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.0100\n",
      "Epoch 00017: val_loss did not improve from 0.00500\n",
      "139/139 [==============================] - 339s 2s/step - loss: 0.0100 - val_loss: 0.0085\n",
      "Epoch 18/100\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.0077\n",
      "Epoch 00018: val_loss did not improve from 0.00500\n",
      "139/139 [==============================] - 364s 3s/step - loss: 0.0077 - val_loss: 0.0186\n",
      "Epoch 19/100\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.0089\n",
      "Epoch 00019: val_loss did not improve from 0.00500\n",
      "139/139 [==============================] - 363s 3s/step - loss: 0.0089 - val_loss: 0.0160\n",
      "Epoch 20/100\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.0100\n",
      "Epoch 00020: val_loss did not improve from 0.00500\n",
      "139/139 [==============================] - 366s 3s/step - loss: 0.0100 - val_loss: 0.0379\n",
      "Epoch 21/100\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.0934\n",
      "Epoch 00021: val_loss did not improve from 0.00500\n",
      "139/139 [==============================] - 367s 3s/step - loss: 0.0934 - val_loss: 77608800.0000\n",
      "Epoch 22/100\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.0446\n",
      "Epoch 00022: val_loss did not improve from 0.00500\n",
      "139/139 [==============================] - 367s 3s/step - loss: 0.0446 - val_loss: 0.0114\n",
      "Epoch 23/100\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.0092\n",
      "Epoch 00023: val_loss did not improve from 0.00500\n",
      "139/139 [==============================] - 365s 3s/step - loss: 0.0092 - val_loss: 0.0108\n",
      "Epoch 24/100\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.0071\n",
      "Epoch 00024: val_loss did not improve from 0.00500\n",
      "139/139 [==============================] - 366s 3s/step - loss: 0.0071 - val_loss: 0.0124\n",
      "Epoch 25/100\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.0065\n",
      "Epoch 00025: val_loss did not improve from 0.00500\n",
      "139/139 [==============================] - 365s 3s/step - loss: 0.0065 - val_loss: 0.0102\n",
      "Epoch 26/100\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.0068\n",
      "Epoch 00026: val_loss did not improve from 0.00500\n",
      "139/139 [==============================] - 366s 3s/step - loss: 0.0068 - val_loss: 0.0100\n",
      "Epoch 27/100\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.0057\n",
      "Epoch 00027: val_loss did not improve from 0.00500\n",
      "139/139 [==============================] - 368s 3s/step - loss: 0.0057 - val_loss: 0.0051\n",
      "Epoch 28/100\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.0055\n",
      "Epoch 00028: val_loss did not improve from 0.00500\n",
      "139/139 [==============================] - 370s 3s/step - loss: 0.0055 - val_loss: 0.0216\n",
      "Epoch 29/100\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.0078\n",
      "Epoch 00029: val_loss did not improve from 0.00500\n",
      "139/139 [==============================] - 371s 3s/step - loss: 0.0078 - val_loss: 0.0201\n",
      "Epoch 30/100\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.0111\n",
      "Epoch 00030: val_loss did not improve from 0.00500\n",
      "139/139 [==============================] - 370s 3s/step - loss: 0.0111 - val_loss: 0.1592\n",
      "Epoch 31/100\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.0070\n",
      "Epoch 00031: val_loss did not improve from 0.00500\n",
      "139/139 [==============================] - 371s 3s/step - loss: 0.0070 - val_loss: 0.0686\n",
      "Epoch 32/100\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.0120\n",
      "Epoch 00032: val_loss did not improve from 0.00500\n",
      "139/139 [==============================] - 365s 3s/step - loss: 0.0120 - val_loss: 0.0474\n",
      "Epoch 33/100\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.0296\n",
      "Epoch 00033: val_loss did not improve from 0.00500\n",
      "139/139 [==============================] - 366s 3s/step - loss: 0.0296 - val_loss: 1.6371\n",
      "Epoch 34/100\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.0195\n",
      "Epoch 00034: val_loss did not improve from 0.00500\n",
      "139/139 [==============================] - 367s 3s/step - loss: 0.0195 - val_loss: 0.0266\n",
      "Epoch 35/100\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.0265\n",
      "Epoch 00035: val_loss did not improve from 0.00500\n",
      "139/139 [==============================] - 368s 3s/step - loss: 0.0265 - val_loss: 1600.9142\n",
      "Epoch 36/100\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.0086\n",
      "Epoch 00036: val_loss did not improve from 0.00500\n",
      "139/139 [==============================] - 369s 3s/step - loss: 0.0086 - val_loss: 1.1634\n",
      "Epoch 37/100\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.0047\n",
      "Epoch 00037: val_loss did not improve from 0.00500\n",
      "139/139 [==============================] - 370s 3s/step - loss: 0.0047 - val_loss: 0.0223\n",
      "Epoch 38/100\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.0045\n",
      "Epoch 00038: val_loss improved from 0.00500 to 0.00459, saving model to D:/weather/model\\LSMT_Restnet_new_data_my_loss_only_CNN_180days.h5\n",
      "139/139 [==============================] - 433s 3s/step - loss: 0.0045 - val_loss: 0.0046\n",
      "Epoch 39/100\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.0049\n",
      "Epoch 00039: val_loss did not improve from 0.00459\n",
      "139/139 [==============================] - 371s 3s/step - loss: 0.0049 - val_loss: 0.0051\n",
      "Epoch 40/100\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.0041\n",
      "Epoch 00040: val_loss did not improve from 0.00459\n",
      "139/139 [==============================] - 364s 3s/step - loss: 0.0041 - val_loss: 0.0383\n",
      "Epoch 41/100\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.0116\n",
      "Epoch 00041: val_loss did not improve from 0.00459\n",
      "139/139 [==============================] - 370s 3s/step - loss: 0.0116 - val_loss: 0.0169\n",
      "Epoch 42/100\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.0064\n",
      "Epoch 00042: val_loss did not improve from 0.00459\n",
      "139/139 [==============================] - 371s 3s/step - loss: 0.0064 - val_loss: 0.0737\n",
      "Epoch 43/100\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.0055\n",
      "Epoch 00043: val_loss did not improve from 0.00459\n",
      "139/139 [==============================] - 373s 3s/step - loss: 0.0055 - val_loss: 0.0151\n",
      "Epoch 44/100\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.0042\n",
      "Epoch 00044: val_loss did not improve from 0.00459\n",
      "139/139 [==============================] - 372s 3s/step - loss: 0.0042 - val_loss: 0.0127\n",
      "Epoch 45/100\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.0058\n",
      "Epoch 00045: val_loss improved from 0.00459 to 0.00413, saving model to D:/weather/model\\LSMT_Restnet_new_data_my_loss_only_CNN_180days.h5\n",
      "139/139 [==============================] - 443s 3s/step - loss: 0.0058 - val_loss: 0.0041\n",
      "Epoch 46/100\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.0046\n",
      "Epoch 00046: val_loss did not improve from 0.00413\n",
      "139/139 [==============================] - 370s 3s/step - loss: 0.0046 - val_loss: 0.0192\n",
      "Epoch 47/100\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.0043\n",
      "Epoch 00047: val_loss did not improve from 0.00413\n",
      "139/139 [==============================] - 370s 3s/step - loss: 0.0043 - val_loss: 0.0109\n",
      "Epoch 48/100\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.0061\n",
      "Epoch 00048: val_loss did not improve from 0.00413\n",
      "139/139 [==============================] - 372s 3s/step - loss: 0.0061 - val_loss: 16.8825\n",
      "Epoch 49/100\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.0074\n",
      "Epoch 00049: val_loss did not improve from 0.00413\n",
      "139/139 [==============================] - 371s 3s/step - loss: 0.0074 - val_loss: 0.0519\n",
      "Epoch 50/100\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.0103\n",
      "Epoch 00050: val_loss did not improve from 0.00413\n",
      "139/139 [==============================] - 365s 3s/step - loss: 0.0103 - val_loss: 88.8195\n",
      "Epoch 51/100\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.0045\n",
      "Epoch 00051: val_loss did not improve from 0.00413\n",
      "139/139 [==============================] - 362s 3s/step - loss: 0.0045 - val_loss: 74.2521\n",
      "Epoch 52/100\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.0573\n",
      "Epoch 00052: val_loss did not improve from 0.00413\n",
      "139/139 [==============================] - 362s 3s/step - loss: 0.0573 - val_loss: 0.0885\n",
      "Epoch 53/100\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.0107\n",
      "Epoch 00053: val_loss did not improve from 0.00413\n",
      "139/139 [==============================] - 375s 3s/step - loss: 0.0107 - val_loss: 0.0346\n",
      "Epoch 54/100\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.0070\n",
      "Epoch 00054: val_loss did not improve from 0.00413\n",
      "139/139 [==============================] - 354s 3s/step - loss: 0.0070 - val_loss: 0.0070\n",
      "Epoch 55/100\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.0053\n",
      "Epoch 00055: val_loss did not improve from 0.00413\n",
      "139/139 [==============================] - 354s 3s/step - loss: 0.0053 - val_loss: 0.0100\n",
      "Epoch 56/100\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.0043\n",
      "Epoch 00056: val_loss did not improve from 0.00413\n",
      "139/139 [==============================] - 355s 3s/step - loss: 0.0043 - val_loss: 0.0053\n",
      "Epoch 57/100\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.0041\n",
      "Epoch 00057: val_loss improved from 0.00413 to 0.00269, saving model to D:/weather/model\\LSMT_Restnet_new_data_my_loss_only_CNN_180days.h5\n",
      "139/139 [==============================] - 419s 3s/step - loss: 0.0041 - val_loss: 0.0027\n",
      "Epoch 58/100\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 00058: val_loss did not improve from 0.00269\n",
      "139/139 [==============================] - 354s 3s/step - loss: 0.0035 - val_loss: 0.0063\n",
      "Epoch 59/100\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 00059: val_loss improved from 0.00269 to 0.00211, saving model to D:/weather/model\\LSMT_Restnet_new_data_my_loss_only_CNN_180days.h5\n",
      "139/139 [==============================] - 423s 3s/step - loss: 0.0032 - val_loss: 0.0021\n",
      "Epoch 60/100\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 00060: val_loss did not improve from 0.00211\n",
      "139/139 [==============================] - 353s 3s/step - loss: 0.0031 - val_loss: 0.0036\n",
      "Epoch 61/100\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.0029\n",
      "Epoch 00061: val_loss did not improve from 0.00211\n",
      "139/139 [==============================] - 354s 3s/step - loss: 0.0029 - val_loss: 0.0043\n",
      "Epoch 62/100\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.0040\n",
      "Epoch 00062: val_loss did not improve from 0.00211\n",
      "139/139 [==============================] - 354s 3s/step - loss: 0.0040 - val_loss: 0.0029\n",
      "Epoch 63/100\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.0042\n",
      "Epoch 00063: val_loss did not improve from 0.00211\n",
      "139/139 [==============================] - 354s 3s/step - loss: 0.0042 - val_loss: 0.0066\n",
      "Epoch 64/100\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.0029\n",
      "Epoch 00064: val_loss did not improve from 0.00211\n",
      "139/139 [==============================] - 354s 3s/step - loss: 0.0029 - val_loss: 0.0030\n",
      "Epoch 65/100\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 00065: val_loss did not improve from 0.00211\n",
      "139/139 [==============================] - 353s 3s/step - loss: 0.0032 - val_loss: 0.0096\n",
      "Epoch 66/100\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.0043\n",
      "Epoch 00066: val_loss did not improve from 0.00211\n",
      "139/139 [==============================] - 354s 3s/step - loss: 0.0043 - val_loss: 0.0037\n",
      "Epoch 67/100\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.0045\n",
      "Epoch 00067: val_loss did not improve from 0.00211\n",
      "139/139 [==============================] - 353s 3s/step - loss: 0.0045 - val_loss: 0.0026\n",
      "Epoch 68/100\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.0043\n",
      "Epoch 00068: val_loss did not improve from 0.00211\n",
      "139/139 [==============================] - 353s 3s/step - loss: 0.0043 - val_loss: 0.0045\n",
      "Epoch 69/100\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.0037\n",
      "Epoch 00069: val_loss did not improve from 0.00211\n",
      "139/139 [==============================] - 354s 3s/step - loss: 0.0037 - val_loss: 0.0102\n",
      "Epoch 70/100\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 00070: val_loss did not improve from 0.00211\n",
      "139/139 [==============================] - 353s 3s/step - loss: 0.0035 - val_loss: 0.0050\n",
      "Epoch 71/100\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 00071: val_loss improved from 0.00211 to 0.00198, saving model to D:/weather/model\\LSMT_Restnet_new_data_my_loss_only_CNN_180days.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139/139 [==============================] - 414s 3s/step - loss: 0.0035 - val_loss: 0.0020\n",
      "Epoch 72/100\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.0026\n",
      "Epoch 00072: val_loss did not improve from 0.00198\n",
      "139/139 [==============================] - 354s 3s/step - loss: 0.0026 - val_loss: 0.0062\n",
      "Epoch 73/100\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.0029\n",
      "Epoch 00073: val_loss did not improve from 0.00198\n",
      "139/139 [==============================] - 356s 3s/step - loss: 0.0029 - val_loss: 0.0167\n",
      "Epoch 74/100\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 00074: val_loss did not improve from 0.00198\n",
      "139/139 [==============================] - 355s 3s/step - loss: 0.0035 - val_loss: 0.0075\n",
      "Epoch 75/100\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 00075: val_loss did not improve from 0.00198\n",
      "139/139 [==============================] - 355s 3s/step - loss: 0.0031 - val_loss: 0.0047\n",
      "Epoch 76/100\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.0027\n",
      "Epoch 00076: val_loss did not improve from 0.00198\n",
      "139/139 [==============================] - 355s 3s/step - loss: 0.0027 - val_loss: 0.0040\n",
      "Epoch 77/100\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.0038\n",
      "Epoch 00077: val_loss did not improve from 0.00198\n",
      "139/139 [==============================] - 354s 3s/step - loss: 0.0038 - val_loss: 0.0075\n",
      "Epoch 78/100\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 00078: val_loss did not improve from 0.00198\n",
      "139/139 [==============================] - 355s 3s/step - loss: 0.0032 - val_loss: 0.0063\n",
      "Epoch 79/100\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.0041\n",
      "Epoch 00079: val_loss did not improve from 0.00198\n",
      "139/139 [==============================] - 355s 3s/step - loss: 0.0041 - val_loss: 0.0074\n",
      "Epoch 80/100\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 00080: val_loss did not improve from 0.00198\n",
      "139/139 [==============================] - 355s 3s/step - loss: 0.0031 - val_loss: 0.0074\n",
      "Epoch 81/100\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.0076\n",
      "Epoch 00081: val_loss did not improve from 0.00198\n",
      "139/139 [==============================] - 354s 3s/step - loss: 0.0076 - val_loss: 0.0046\n",
      "Epoch 82/100\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.0039\n",
      "Epoch 00082: val_loss did not improve from 0.00198\n",
      "139/139 [==============================] - 355s 3s/step - loss: 0.0039 - val_loss: 0.0111\n",
      "Epoch 83/100\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 00083: val_loss did not improve from 0.00198\n",
      "139/139 [==============================] - 355s 3s/step - loss: 0.0032 - val_loss: 0.0052\n",
      "Epoch 84/100\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 00084: val_loss did not improve from 0.00198\n",
      "139/139 [==============================] - 354s 3s/step - loss: 0.0031 - val_loss: 0.0105\n",
      "Epoch 85/100\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.0050\n",
      "Epoch 00085: val_loss did not improve from 0.00198\n",
      "139/139 [==============================] - 354s 3s/step - loss: 0.0050 - val_loss: 0.0113\n",
      "Epoch 86/100\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.0043\n",
      "Epoch 00086: val_loss did not improve from 0.00198\n",
      "139/139 [==============================] - 356s 3s/step - loss: 0.0043 - val_loss: 0.0069\n",
      "Epoch 87/100\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.0104\n",
      "Epoch 00087: val_loss did not improve from 0.00198\n",
      "139/139 [==============================] - 354s 3s/step - loss: 0.0104 - val_loss: 9.1509\n",
      "Epoch 88/100\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.0092\n",
      "Epoch 00088: val_loss did not improve from 0.00198\n",
      "139/139 [==============================] - 354s 3s/step - loss: 0.0092 - val_loss: 0.0953\n",
      "Epoch 89/100\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.0050\n",
      "Epoch 00089: val_loss did not improve from 0.00198\n",
      "139/139 [==============================] - 355s 3s/step - loss: 0.0050 - val_loss: 0.0286\n",
      "Epoch 90/100\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.0030\n",
      "Epoch 00090: val_loss did not improve from 0.00198\n",
      "139/139 [==============================] - 355s 3s/step - loss: 0.0030 - val_loss: 0.0150\n",
      "Epoch 91/100\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 00091: val_loss did not improve from 0.00198\n",
      "139/139 [==============================] - 354s 3s/step - loss: 0.0035 - val_loss: 0.0048\n",
      "Epoch 92/100\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.0029\n",
      "Epoch 00092: val_loss did not improve from 0.00198\n",
      "139/139 [==============================] - 354s 3s/step - loss: 0.0029 - val_loss: 0.0024\n",
      "Epoch 93/100\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.0025\n",
      "Epoch 00093: val_loss did not improve from 0.00198\n",
      "139/139 [==============================] - 355s 3s/step - loss: 0.0025 - val_loss: 0.0410\n",
      "Epoch 94/100\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.0029\n",
      "Epoch 00094: val_loss did not improve from 0.00198\n",
      "139/139 [==============================] - 355s 3s/step - loss: 0.0029 - val_loss: 0.0099\n",
      "Epoch 95/100\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.0030\n",
      "Epoch 00095: val_loss did not improve from 0.00198\n",
      "139/139 [==============================] - 354s 3s/step - loss: 0.0030 - val_loss: 0.0023\n",
      "Epoch 96/100\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.0028\n",
      "Epoch 00096: val_loss did not improve from 0.00198\n",
      "139/139 [==============================] - 354s 3s/step - loss: 0.0028 - val_loss: 0.0182\n",
      "Epoch 97/100\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.0034\n",
      "Epoch 00097: val_loss did not improve from 0.00198\n",
      "139/139 [==============================] - 355s 3s/step - loss: 0.0034 - val_loss: 0.4834\n",
      "Epoch 98/100\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.0057\n",
      "Epoch 00098: val_loss did not improve from 0.00198\n",
      "139/139 [==============================] - 354s 3s/step - loss: 0.0057 - val_loss: 0.0274\n",
      "Epoch 99/100\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.0155\n",
      "Epoch 00099: val_loss did not improve from 0.00198\n",
      "139/139 [==============================] - 354s 3s/step - loss: 0.0155 - val_loss: 18626.3145\n",
      "Epoch 100/100\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.0083\n",
      "Epoch 00100: val_loss did not improve from 0.00198\n",
      "139/139 [==============================] - 354s 3s/step - loss: 0.0083 - val_loss: 0.5632\n"
     ]
    }
   ],
   "source": [
    "model_checkpoint_callback=ModelCheckpoint(Path_model, monitor='val_loss', verbose=1, save_best_only=True)\n",
    "model.compile(optimizer = 'adam', loss = mcustom_loss,run_eagerly=True)\n",
    "\n",
    "histroy=model.fit([Train_Pdf],Label,\n",
    "          batch_size=16,\n",
    "          #validation_data=([Valid_Pdf,Valid_Lstm],Valid_Label),\n",
    "          validation_split=0.2,\n",
    "          epochs=100,\n",
    "          callbacks=[model_checkpoint_callback]\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d8c338d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x23de1e5b730>]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(histroy.history['loss']) \n",
    "plt.plot(histroy.history['val_loss']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d99dcc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
